{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea938c84",
   "metadata": {},
   "source": [
    "# üß† Decision Tree Case Studies ‚Äî Answers Notebook\n",
    "This notebook contains answers and detailed explanations for all 10 case studies using **Entropy**, **Information Gain**, and **Gini Impurity** metrics.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6498ea6",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Loan Approval Prediction ‚Äî Using Entropy & Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset\n",
    "data = {\n",
    "    'Income': ['High', 'High', 'Low', 'Low'],\n",
    "    'CreditScore': ['Good', 'Bad', 'Good', 'Bad'],\n",
    "    'LoanApproved': ['Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded = pd.get_dummies(df[['Income', 'CreditScore']])\n",
    "y = df['LoanApproved'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Train Decision Tree using Entropy\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model.fit(df_encoded, y)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model, feature_names=df_encoded.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44cb9a",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Root node = **CreditScore** (highest Information Gain)\n",
    "- Rule: If CreditScore=Good ‚Üí Approve Loan (Yes), else check Income.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33262b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Student Exam Pass Prediction ‚Äî Using Gini Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66047c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'HoursStudied': ['High','Medium','Low','Low','High'],\n",
    "    'Attendance': ['Good','Good','Poor','Good','Poor'],\n",
    "    'Passed': ['Yes','Yes','No','No','Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df[['HoursStudied','Attendance']])\n",
    "y = df['Passed'].map({'Yes':1,'No':0})\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "model.fit(df_encoded, y)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model, feature_names=df_encoded.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394fd34",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Best Split = **HoursStudied** (lower Gini)\n",
    "- Students with High or Medium study hours mostly pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018aa31",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Employee Attrition ‚Äî Using Entropy & Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Age': [25,45,30,50],\n",
    "    'Overtime': ['Yes','No','Yes','No'],\n",
    "    'SalaryLevel': ['Low','High','Medium','High'],\n",
    "    'Attrition': ['Yes','No','Yes','No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df[['Overtime','SalaryLevel']])\n",
    "y = df['Attrition'].map({'Yes':1,'No':0})\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model.fit(df_encoded, y)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model, feature_names=df_encoded.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83ba7c",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Best root = **Overtime** (higher Information Gain)\n",
    "- Employees doing Overtime are more likely to leave.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd67a5",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Customer Churn ‚Äî Using Entropy & IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Contract': ['Month-to-Month','One Year','Two Year','Month-to-Month'],\n",
    "    'MonthlyCharges': ['High','Low','Low','Medium'],\n",
    "    'Churn': ['Yes','No','No','Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df[['Contract','MonthlyCharges']])\n",
    "y = df['Churn'].map({'Yes':1,'No':0})\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model.fit(df_encoded, y)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model, feature_names=df_encoded.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e4517",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Best root = **Contract** (Month-to-Month ‚Üí High churn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6ca0d",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Weather-based Play Decision ‚Äî Classic ID3 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec03139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Outlook': ['Sunny','Sunny','Overcast','Rain','Rain'],\n",
    "    'Temperature': ['Hot','Hot','Hot','Mild','Cool'],\n",
    "    'Humidity': ['High','High','High','High','Normal'],\n",
    "    'Wind': ['Weak','Strong','Weak','Weak','Weak'],\n",
    "    'Play': ['No','No','Yes','Yes','Yes']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df[['Outlook','Temperature','Humidity','Wind']])\n",
    "y = df['Play'].map({'Yes':1,'No':0})\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model.fit(df_encoded, y)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_tree(model, feature_names=df_encoded.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc667cc",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- Best root = **Outlook** (highest Information Gain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8625",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Purchase Prediction (E-commerce) ‚Äî Using Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4dde1",
   "metadata": {},
   "source": [
    "**Result:** Best Split = Time on Website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045caa9f",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Disease Diagnosis ‚Äî Using Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc22602",
   "metadata": {},
   "source": [
    "**Result:** Best Feature = Fever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc84fe26",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Spam Email Classification ‚Äî Using Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968bdb8",
   "metadata": {},
   "source": [
    "**Result:** Best Feature = Contains_Free\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d7f60",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Credit Card Fraud Detection ‚Äî Using Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4aa2e6",
   "metadata": {},
   "source": [
    "**Result:** Best Feature = Foreign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63a443",
   "metadata": {},
   "source": [
    "## 10Ô∏è‚É£ Car Purchase Decision ‚Äî Using Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9056ccf",
   "metadata": {},
   "source": [
    "**Result:** Best Feature = Income\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e9979",
   "metadata": {},
   "source": [
    "# üß† Decision Tree Case Studies ‚Äî Answers (Detailed for 6‚Äì10)\n",
    "This notebook provides full code, datasets, and explanations for case studies 6 through 10. Each case includes dataset creation, encoding, model training, visualization, and an explicit determination of the best feature / root split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb5c0b",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Purchase Prediction (E-commerce) ‚Äî Gini Impurity\n",
    "**Goal:** Predict `Purchased` using `Age` and `Time on Website`.\n",
    "\n",
    "We use Gini-criterion Decision Tree and check feature importances to decide the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data6 = {\n",
    "    'Age': [23,35,31,22],\n",
    "    'TimeOnSite': [15,45,35,10],\n",
    "    'Purchased': ['No','Yes','Yes','No']\n",
    "}\n",
    "df6 = pd.DataFrame(data6)\n",
    "df6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f26ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target\n",
    "X6 = df6[['Age','TimeOnSite']]\n",
    "y6 = df6['Purchased'].map({'Yes':1,'No':0})\n",
    "\n",
    "# Train decision tree with Gini\n",
    "model6 = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "model6.fit(X6, y6)\n",
    "\n",
    "# Feature importances and tree plot\n",
    "print(\"Feature importances:\", dict(zip(X6.columns, model6.feature_importances_)))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model6, feature_names=X6.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e983c74",
   "metadata": {},
   "source": [
    "**Conclusion (Case 6):**\n",
    "- Feature importances show which of `Age` or `TimeOnSite` the model used most.\n",
    "- The feature with the higher importance is the recommended root split. (Interpret from the printed importances above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b988a0",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Disease Diagnosis ‚Äî Entropy & Information Gain\n",
    "**Goal:** Predict `Flu` using `Fever` and `Cough`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data7 = {\n",
    "    'Fever': ['Yes','Yes','No','No'],\n",
    "    'Cough': ['Yes','No','Yes','No'],\n",
    "    'Flu': ['Yes','Yes','No','No']\n",
    "}\n",
    "df7 = pd.DataFrame(data7)\n",
    "df7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode and train with entropy criterion\n",
    "X7 = pd.get_dummies(df7[['Fever','Cough']])\n",
    "y7 = df7['Flu'].map({'Yes':1,'No':0})\n",
    "\n",
    "model7 = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model7.fit(X7, y7)\n",
    "\n",
    "print(\"Feature importances:\", dict(zip(X7.columns, model7.feature_importances_)))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model7, feature_names=X7.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a3337",
   "metadata": {},
   "source": [
    "**Conclusion (Case 7):**\n",
    "- Compare importances for `Fever_Yes` vs `Cough_Yes` (or the encoded features). The highest importance indicates the best root feature (Fever or Cough)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897aa1b",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Spam Email Classification ‚Äî Entropy & Information Gain\n",
    "**Goal:** Predict `Spam` using presence of `Free` and `Click`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data8 = {\n",
    "    'Contains_Free': ['Yes','Yes','No','No'],\n",
    "    'Contains_Click': ['Yes','No','Yes','No'],\n",
    "    'Spam': ['Yes','Yes','No','No']\n",
    "}\n",
    "df8 = pd.DataFrame(data8)\n",
    "df8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X8 = pd.get_dummies(df8[['Contains_Free','Contains_Click']])\n",
    "y8 = df8['Spam'].map({'Yes':1,'No':0})\n",
    "\n",
    "model8 = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model8.fit(X8, y8)\n",
    "\n",
    "print(\"Feature importances:\", dict(zip(X8.columns, model8.feature_importances_)))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model8, feature_names=X8.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e4d82",
   "metadata": {},
   "source": [
    "**Conclusion (Case 8):**\n",
    "- The attribute (`Contains_Free` or `Contains_Click`) with higher importance is the best split. In small synthetic datasets like this, often `Contains_Free` explains spam strongly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aade1a2",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Credit Card Fraud Detection ‚Äî Gini Impurity\n",
    "**Goal:** Predict `Fraud` using `Amount` (High/Low) and `Foreign` (Yes/No)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056373dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data9 = {\n",
    "    'Amount': ['High','High','Low','Low'],\n",
    "    'Foreign': ['Yes','No','No','Yes'],\n",
    "    'Fraud': ['Yes','No','No','Yes']\n",
    "}\n",
    "df9 = pd.DataFrame(data9)\n",
    "df9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X9 = pd.get_dummies(df9[['Amount','Foreign']])\n",
    "y9 = df9['Fraud'].map({'Yes':1,'No':0})\n",
    "\n",
    "model9 = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "model9.fit(X9, y9)\n",
    "\n",
    "print(\"Feature importances:\", dict(zip(X9.columns, model9.feature_importances_)))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plot_tree(model9, feature_names=X9.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456f819",
   "metadata": {},
   "source": [
    "**Conclusion (Case 9):**\n",
    "- The `Foreign_Yes` or `Amount_High` importance reveals the preferred split; higher importance indicates the root. In this dataset `Foreign` often separates fraud effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74b75d",
   "metadata": {},
   "source": [
    "## üîü Car Purchase Decision ‚Äî Entropy & Information Gain\n",
    "**Goal:** Predict `Buy Car` using `Income` and `Age Group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data10 = {\n",
    "    'Income': ['High','Medium','High','Low'],\n",
    "    'AgeGroup': ['30-40','20-30','40-50','20-30'],\n",
    "    'BuyCar': ['Yes','No','Yes','No']\n",
    "}\n",
    "df10 = pd.DataFrame(data10)\n",
    "df10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dbdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X10 = pd.get_dummies(df10[['Income','AgeGroup']])\n",
    "y10 = df10['BuyCar'].map({'Yes':1,'No':0})\n",
    "\n",
    "model10 = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "model10.fit(X10, y10)\n",
    "\n",
    "print(\"Feature importances:\", dict(zip(X10.columns, model10.feature_importances_)))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plot_tree(model10, feature_names=X10.columns, class_names=['No','Yes'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106f399",
   "metadata": {},
   "source": [
    "**Conclusion (Case 10):**\n",
    "- The one-hot encoded feature with the largest importance (for example `Income_High`) indicates which attribute (Income or AgeGroup) is most predictive; choose that attribute as the root split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bd897",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## How to interpret results\n",
    "- After running each code block, check the printed feature importances to see which feature the tree prioritized.\n",
    "- The feature with the highest importance is the recommended root split (highest information gain / impurity reduction).\n",
    "\n",
    "If you want, I can now merge these detailed cells into your existing notebook (`Decision_Trees_CBA.ipynb`) to exactly match its layout and styling."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
